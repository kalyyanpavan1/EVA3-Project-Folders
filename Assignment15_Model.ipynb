{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled44.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1YF/p+S2wXTYchRcolbT9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalyyanpavan1/EVA3-Project-Folders/blob/Model/Assignment15_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEEiXwhZRguw",
        "colab_type": "text"
      },
      "source": [
        "**Create the Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQZNMBz-Rpv0",
        "colab_type": "text"
      },
      "source": [
        "**Initialization function similar to Pytorch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC-rjnnBSKk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialization function similar to Pytorch\n",
        "def init_pytorch(shape, dtype=tf.float32, partition_info=None):\n",
        "  fan = np.prod(shape[:-1])\n",
        "  bound = 1 / math.sqrt(fan)\n",
        "  return tf.random.uniform(shape, minval=-bound, maxval=bound, dtype=dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWr6akhTSP9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Single Convolution Block\n",
        "class ConvBN(tf.keras.Model):\n",
        "  def __init__(self, c_out):\n",
        "    super().__init__()\n",
        "    self.conv = tf.keras.layers.Conv2D(filters=c_out, kernel_size=3, padding=\"SAME\", kernel_initializer=init_pytorch, use_bias=False)\n",
        "    self.bn = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.nn.relu(self.bn(self.conv(inputs)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05uqH2iGST_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Residual block\n",
        "class ResBlk(tf.keras.Model):\n",
        "  def __init__(self, c_out, pool, res = False):\n",
        "    super().__init__()\n",
        "    self.conv_bn = ConvBN(c_out)\n",
        "    self.pool = pool\n",
        "    self.res = res\n",
        "    if self.res:\n",
        "      self.res1 = ConvBN(c_out)\n",
        "      self.res2 = ConvBN(c_out)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    h = self.pool(self.conv_bn(inputs))\n",
        "    if self.res:\n",
        "      h = h + self.res2(self.res1(h))\n",
        "    return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6T7AHAkSZj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defing the David Net Model.\n",
        "\n",
        "class DavidNet(tf.keras.Model):\n",
        "  def __init__(self, c=64, weight=0.125):\n",
        "    super().__init__()\n",
        "    pool = tf.keras.layers.MaxPooling2D()\n",
        "    self.init_conv_bn = ConvBN(c)\n",
        "    self.blk1 = ResBlk(c*2, pool, res = True)\n",
        "    self.blk2 = ResBlk(c*4, pool)\n",
        "    self.blk3 = ResBlk(c*8, pool, res = True)\n",
        "    self.pool = tf.keras.layers.GlobalMaxPool2D()\n",
        "    self.linear = tf.keras.layers.Dense(10, kernel_initializer=init_pytorch, use_bias=False)\n",
        "    self.weight = weight\n",
        "\n",
        "  def call(self, x, y):\n",
        "    h = self.pool(self.blk3(self.blk2(self.blk1(self.init_conv_bn(x)))))\n",
        "    h = self.linear(h) * self.weight\n",
        "    ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=h, labels=y)\n",
        "    loss = tf.reduce_sum(ce)\n",
        "    correct = tf.reduce_sum(tf.cast(tf.math.equal(tf.argmax(h, axis = 1), y), tf.float32))\n",
        "    return loss, correct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLYaxvLhShZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cutout Function 1\n",
        "from PIL import Image\n",
        "class Cutout(object):\n",
        "    def __init__(self, length=10):\n",
        "        self.length = length\n",
        "\n",
        "    def __call__(self, p, img):\n",
        "      cutout_im = np.zeros_like(img)\n",
        "      for i in range(img.shape[0]):\n",
        "        p_1 = np.random.rand() \n",
        "        im = img[i]\n",
        "        im = np.array(im)\n",
        "        if p_1 > p:\n",
        "          cutout_im[i] = im\n",
        "        else:\n",
        "          mask_val = im.mean()\n",
        "\n",
        "          top = np.random.randint(0, im.shape[0])\n",
        "          left = np.random.randint(0, im.shape[1])\n",
        "          bottom = top + self.length\n",
        "          right = left + self.length\n",
        "\n",
        "          im[top:bottom, left:right, :] = mask_val\n",
        "\n",
        "          im = Image.fromarray(im)\n",
        "          cutout_im[i] = im\n",
        "      return cutout_im\n",
        "\n",
        "cutout=Cutout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wkWxtSsSpzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cutout Function 2\n",
        "\n",
        "def random_erasing(img, probability = 0.5, sl = 0.02, sh = 0.4, r1 = 0.3):\n",
        "    '''\n",
        "    img is a 3-D variable (ex: tf.Variable(image, validate_shape=False) ) and  HWC order\n",
        "    '''\n",
        "    # HWC order\n",
        "    \n",
        "    with tf.init_scope():\n",
        "\n",
        "      img = tf.Variable(tf.convert_to_tensor(img))\n",
        "      height = tf.shape(img)[0]\n",
        "      width = tf.shape(img)[1]\n",
        "      channel = tf.shape(img)[2]\n",
        "      area = tf.cast(width*height, tf.float32)\n",
        "\n",
        "      erase_area_low_bound = tf.cast(tf.round(tf.sqrt(sl * area * r1)), tf.int32)\n",
        "      erase_area_up_bound = tf.cast(tf.round(tf.sqrt((sh * area) / r1)), tf.int32)\n",
        "      h_upper_bound = tf.minimum(erase_area_up_bound, height)\n",
        "      w_upper_bound = tf.minimum(erase_area_up_bound, width)\n",
        "\n",
        "      h = tf.random.uniform([], erase_area_low_bound, h_upper_bound, tf.int32)\n",
        "      w = tf.random.uniform([], erase_area_low_bound, w_upper_bound, tf.int32)\n",
        "\n",
        "      x1 = tf.random.uniform([], 0, height+1 - h, tf.int32)\n",
        "      y1 = tf.random.uniform([], 0, width+1 - w, tf.int32)\n",
        "\n",
        "      erase_area = tf.cast(tf.random.uniform([h, w, channel], 0, 255, tf.int32), tf.uint8)\n",
        "\n",
        "      erasing_img = img[x1:x1+h, y1:y1+w, :].assign(erase_area)\n",
        "\n",
        "      return tf.cond(tf.random.uniform([], 0, 1) > probability, lambda: img, lambda: erasing_img)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}